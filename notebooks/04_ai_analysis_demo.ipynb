{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fed Minutes AI Analysis Demo\n",
    "\n",
    "This notebook demonstrates Phase 3 AI-powered analysis capabilities:\n",
    "- **RAG (Retrieval-Augmented Generation)** for intelligent Q&A\n",
    "- **Historical research** with LLM-powered insights\n",
    "- **Time period analysis** and trend detection\n",
    "- **Topic evolution** tracking over time\n",
    "\n",
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load environment variables from .env file\nfrom dotenv import load_dotenv\nload_dotenv()  # This loads your OPENAI_API_KEY from .env file\n\nimport sys\nimport os\nsys.path.append('..')\n\n# Core imports\nimport warnings\nwarnings.filterwarnings('ignore', category=FutureWarning)\n\nfrom src.utils.config import load_config\nfrom src.phase3_ai_analysis import create_rag_pipeline, create_llm_client\nfrom src.phase2_knowledge_base import create_search_interface\n\nimport pandas as pd\nfrom datetime import datetime\nimport json\n\n# Verify API key is loaded\napi_key_status = bool(os.getenv('OPENAI_API_KEY'))\nprint(f'✅ API key loaded from .env: {api_key_status}')\nif not api_key_status:\n    print('⚠️  No OPENAI_API_KEY found in .env file - will use mock responses')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load configuration\nconfig = load_config()\nprint(\"Configuration loaded successfully\")\nprint(f\"LLM Provider: {config.get('llm', {}).get('provider', 'openai')}\")\nprint(f\"Model: {config.get('llm', {}).get('model', 'gpt-4')}\")\n\n# Show available LLM options\nprint(\"\\n📋 Available LLM Providers:\")\nprint(\"- OpenAI: Requires OPENAI_API_KEY in .env\")\nprint(\"- Anthropic: Requires ANTHROPIC_API_KEY in .env\")  \nprint(\"- Ollama: Local models, no API key required\")\nprint(\"- Mock: Test mode without any LLM\")\n\n# Check for Ollama if configured\nif config.get('llm', {}).get('provider') == 'ollama':\n    print(f\"\\n🦙 Ollama Configuration:\")\n    print(f\"   Model: {config.get('llm', {}).get('model')}\")\n    print(f\"   Base URL: {config.get('llm', {}).get('base_url')}\")\n    print(\"   Note: Make sure Ollama is running with your model installed\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Initialize AI Analysis System\n\n**Note**: This demo supports multiple LLM providers:\n\n### 🌐 **API-Based Providers** (Require API Keys):\n- **OpenAI**: Set `OPENAI_API_KEY` in your `.env` file\n- **Anthropic**: Set `ANTHROPIC_API_KEY` in your `.env` file\n\n### 🦙 **Local Provider** (No API Key Required):\n- **Ollama**: Install Ollama and download a model:\n\n  **On macOS:**\n  ```bash\n  # Option 1: Using Homebrew\n  brew install ollama\n  \n  # Option 2: Download from https://ollama.com/download/mac\n  \n  # After installation, pull a model:\n  ollama pull mistral:7b\n  ```\n  \n  **On Linux:**\n  ```bash\n  curl -fsSL https://ollama.ai/install.sh | sh\n  ollama pull mistral:7b\n  ```\n  \n  **Then edit config/config.yaml:**\n  ```yaml\n  llm:\n    provider: \"ollama\"\n    model: \"mistral:7b\"\n  ```\n\n### 🧪 **Test Mode**:\n- **Mock**: Uses mock responses for testing without any LLM"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the RAG pipeline\n",
    "print(\"Initializing AI Analysis System...\")\n",
    "rag = create_rag_pipeline(config)\n",
    "\n",
    "# Check what LLM provider we're using\n",
    "print(f\"\\nLLM Client: {rag.llm.__class__.__name__}\")\n",
    "print(f\"Available: {rag.llm.is_available()}\")\n",
    "\n",
    "if rag.llm.__class__.__name__ == \"MockLLMClient\":\n",
    "    print(\"\\n⚠️  Using mock LLM responses for demo purposes\")\n",
    "    print(\"   Set OPENAI_API_KEY or ANTHROPIC_API_KEY for real analysis\")\n",
    "else:\n",
    "    print(f\"\\n✅ Real LLM analysis available with {rag.llm.__class__.__name__}\")\n",
    "\n",
    "print(\"\\nAI Analysis System ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## 🦙 Optional: Configure for Ollama (Local LLM)\n\nIf you want to use a local model instead of OpenAI/Anthropic, you can configure Ollama:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# OPTIONAL: Test Ollama configuration\n# Uncomment and run this cell to use Ollama instead of OpenAI/Anthropic\n\n# # Override config to use Ollama\n# config['llm'] = {\n#     'provider': 'ollama',\n#     'model': 'mistral:7b',  # or 'llama3:8b', 'phi3:mini'\n#     'temperature': 0.1,\n#     'max_tokens': 1000,\n#     'base_url': 'http://localhost:11434'\n# }\n\n# # Test Ollama availability\n# from src.phase3_ai_analysis import OllamaClient\n# ollama_test = OllamaClient(config['llm']['model'])\n# if ollama_test.is_available():\n#     print(f\"✅ Ollama is available with model: {config['llm']['model']}\")\n#     print(\"   You can now run all the analysis cells with local LLM!\")\n# else:\n#     print(\"❌ Ollama not available. To fix:\")\n#     print(\"   1. Install Ollama: https://ollama.ai/download\")\n#     print(f\"   2. Run: ollama pull {config['llm']['model']}\")\n#     print(\"   3. Make sure Ollama is running\")\n\n# # Reinitialize RAG with Ollama\n# rag = create_rag_pipeline(config)\n# print(f\"\\nRAG pipeline reinitialized with {rag.llm.__class__.__name__}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Intelligent Q&A with RAG\n",
    "\n",
    "Ask questions about Fed Minutes content and get AI-powered answers with citations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: General policy question\n",
    "question = \"What were the Federal Reserve's main concerns about inflation in 1971?\"\n",
    "print(f\"Question: {question}\\n\")\n",
    "\n",
    "response = rag.answer_question(\n",
    "    question=question,\n",
    "    date_range=(\"1971-01-01\", \"1971-12-31\"),\n",
    "    max_context_chunks=5\n",
    ")\n",
    "\n",
    "print(f\"Answer: {response.answer}\\n\")\n",
    "print(f\"Confidence: {response.confidence:.2f}\")\n",
    "print(f\"Citations: {len(response.citations)} meetings referenced\")\n",
    "print(f\"Tokens used: {response.tokens_used}\\n\")\n",
    "\n",
    "# Show citations\n",
    "if response.citations:\n",
    "    print(\"Meeting References:\")\n",
    "    for citation in response.citations[:3]:  # Show first 3\n",
    "        print(f\"  - {citation['meeting']} ({citation['date']})\")\n",
    "    if len(response.citations) > 3:\n",
    "        print(f\"  ... and {len(response.citations) - 3} more\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Nixon Shock specific question\n",
    "question = \"How did the Federal Reserve respond to the Nixon Shock in August 1971?\"\n",
    "print(f\"Question: {question}\\n\")\n",
    "\n",
    "response = rag.answer_question(\n",
    "    question=question,\n",
    "    date_range=(\"1971-08-01\", \"1971-12-31\"),\n",
    "    max_context_chunks=6\n",
    ")\n",
    "\n",
    "print(f\"Answer: {response.answer}\\n\")\n",
    "print(f\"Confidence: {response.confidence:.2f}\")\n",
    "print(f\"Context chunks analyzed: {len(response.context.chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: Bretton Woods question\n",
    "question = \"What did the Fed discuss about international monetary system changes in 1972-1973?\"\n",
    "print(f\"Question: {question}\\n\")\n",
    "\n",
    "response = rag.answer_question(\n",
    "    question=question,\n",
    "    date_range=(\"1972-01-01\", \"1973-12-31\"),\n",
    "    max_context_chunks=5\n",
    ")\n",
    "\n",
    "print(f\"Answer: {response.answer}\\n\")\n",
    "print(f\"Confidence: {response.confidence:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Period Summary Analysis\n",
    "\n",
    "Generate comprehensive summaries of Fed discussions during specific time periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of Nixon Shock period\n",
    "print(\"Generating summary for Nixon Shock period (Aug-Dec 1971)...\\n\")\n",
    "\n",
    "summary = rag.summarize_period(\n",
    "    start_date=\"1971-08-01\",\n",
    "    end_date=\"1971-12-31\",\n",
    "    topics=[\"monetary policy\", \"nixon shock\", \"exchange rates\", \"international\"],\n",
    "    max_chunks=8\n",
    ")\n",
    "\n",
    "print(f\"Period Summary (Aug-Dec 1971):\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"{summary.answer}\\n\")\n",
    "\n",
    "print(f\"Analysis based on {len(summary.context.chunks)} meeting excerpts\")\n",
    "print(f\"Confidence: {summary.confidence:.2f}\")\n",
    "print(f\"Meetings referenced: {len(summary.citations)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of Bretton Woods collapse period\n",
    "print(\"Generating summary for Bretton Woods collapse period (1972-1973)...\\n\")\n",
    "\n",
    "summary = rag.summarize_period(\n",
    "    start_date=\"1972-01-01\",\n",
    "    end_date=\"1973-12-31\",\n",
    "    topics=[\"bretton woods\", \"international monetary\", \"exchange rates\", \"gold\"],\n",
    "    max_chunks=10\n",
    ")\n",
    "\n",
    "print(f\"Period Summary (1972-1973):\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"{summary.answer}\\n\")\n",
    "\n",
    "print(f\"Analysis based on {len(summary.context.chunks)} meeting excerpts\")\n",
    "print(f\"Confidence: {summary.confidence:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Topic Evolution Analysis\n",
    "\n",
    "Track how Fed discussions of specific topics evolved over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze evolution of inflation discussions\n",
    "print(\"Analyzing evolution of inflation discussions (1969-1973)...\\n\")\n",
    "\n",
    "evolution = rag.analyze_topic_evolution(\n",
    "    topic=\"inflation price stability\",\n",
    "    start_year=1969,\n",
    "    end_year=1973,\n",
    "    chunks_per_year=3\n",
    ")\n",
    "\n",
    "print(f\"Topic Evolution: Inflation Discussions (1969-1973)\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"{evolution.answer}\\n\")\n",
    "\n",
    "print(f\"Analysis covers {evolution.context.search_params['years']}\")\n",
    "print(f\"Total meeting excerpts analyzed: {len(evolution.context.chunks)}\")\n",
    "print(f\"Confidence: {evolution.confidence:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze evolution of international monetary discussions\n",
    "print(\"Analyzing international monetary system discussions (1970-1973)...\\n\")\n",
    "\n",
    "evolution = rag.analyze_topic_evolution(\n",
    "    topic=\"international monetary system exchange rates\",\n",
    "    start_year=1970,\n",
    "    end_year=1973,\n",
    "    chunks_per_year=4\n",
    ")\n",
    "\n",
    "print(f\"Topic Evolution: International Monetary System (1970-1973)\")\n",
    "print(f\"{'='*65}\")\n",
    "print(f\"{evolution.answer}\\n\")\n",
    "\n",
    "print(f\"Total excerpts analyzed: {len(evolution.context.chunks)}\")\n",
    "print(f\"Confidence: {evolution.confidence:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Comparative Period Analysis\n",
    "\n",
    "Compare Fed discussions between different time periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare pre and post Nixon Shock periods\n",
    "print(\"Comparing Fed discussions: Pre vs Post Nixon Shock...\\n\")\n",
    "\n",
    "comparison = rag.compare_periods(\n",
    "    period1=(\"1970-01-01\", \"1971-07-31\"),  # Pre-Nixon Shock\n",
    "    period2=(\"1971-08-15\", \"1972-06-30\"),  # Post-Nixon Shock\n",
    "    aspects=[\"monetary policy\", \"inflation\", \"international\", \"exchange rates\"]\n",
    ")\n",
    "\n",
    "print(f\"Period Comparison: Pre vs Post Nixon Shock\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Pre-Nixon Shock: 1970-01-01 to 1971-07-31\")\n",
    "print(f\"Post-Nixon Shock: 1971-08-15 to 1972-06-30\")\n",
    "print(f\"\\n{comparison.answer}\\n\")\n",
    "\n",
    "print(f\"Analysis based on {len(comparison.context.chunks)} meeting excerpts\")\n",
    "print(f\"Confidence: {comparison.confidence:.2f}\")\n",
    "print(f\"Meetings referenced: {len(comparison.citations)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Summary and Next Steps\n\nThis notebook demonstrates the core capabilities of Phase 3 AI analysis:\n\n### What We've Built:\n✅ **Intelligent Q&A System**: Ask natural language questions about Fed Minutes content  \n✅ **Period Summarization**: Generate comprehensive summaries of Fed discussions during specific timeframes  \n✅ **Topic Evolution**: Track how Fed thinking evolved on key topics over time  \n✅ **Comparative Analysis**: Compare Fed discussions between different periods  \n✅ **Citation System**: All answers include references to source meetings  \n✅ **Confidence Scoring**: Quality assessment for each analysis  \n✅ **Local LLM Support**: Use Ollama for free, unlimited analysis without API keys\n\n### Key Features:\n- **RAG Pipeline**: Combines semantic search with LLM analysis\n- **Multi-Provider Support**: Works with OpenAI, Anthropic, Ollama, or mock responses\n- **Temporal Analysis**: Date-aware search and analysis\n- **Research-Ready**: Designed for academic and policy research\n- **Privacy Option**: Keep all data local with Ollama\n\n### LLM Provider Comparison:\n| Provider | Cost | Privacy | Speed | Quality | Setup |\n|----------|------|---------|-------|---------|-------|\n| OpenAI | $ per use | Cloud | Fast | Excellent | API key |\n| Anthropic | $ per use | Cloud | Fast | Excellent | API key |\n| Ollama | Free | Local | Medium | Good | Install app |\n| Mock | Free | Local | Instant | Mock | None |\n\n### Try These Research Questions:\n- \"How did the Fed view international cooperation during the Bretton Woods crisis?\"\n- \"What were the main disagreements in Fed meetings during 1971?\"\n- \"How did Fed concerns about unemployment change from 1969 to 1973?\"\n- \"What role did William McChesney Martin play in monetary policy decisions?\"\n\n### Phase 4 Vision:\n- **Automated Research Reports**: Generate comprehensive analysis documents\n- **Pattern Recognition**: Discover hidden relationships and trends\n- **Decision Tree Analysis**: Map Fed decision-making processes\n- **Interactive Dashboard**: Web interface for researchers"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive Q&A - modify this cell to ask your own questions\n",
    "\n",
    "# Your question here:\n",
    "your_question = \"What did the Fed discuss about wage and price controls?\"\n",
    "date_range = (\"1971-01-01\", \"1972-12-31\")  # Optional date filter\n",
    "\n",
    "print(f\"Your Question: {your_question}\")\n",
    "if date_range:\n",
    "    print(f\"Date Range: {date_range[0]} to {date_range[1]}\")\n",
    "print()\n",
    "\n",
    "response = rag.answer_question(\n",
    "    question=your_question,\n",
    "    date_range=date_range,\n",
    "    max_context_chunks=6\n",
    ")\n",
    "\n",
    "print(f\"Answer: {response.answer}\\n\")\n",
    "print(f\"Confidence: {response.confidence:.2f}\")\n",
    "print(f\"Context: {len(response.context.chunks)} chunks analyzed\")\n",
    "\n",
    "# Show some context for verification\n",
    "if response.context.chunks:\n",
    "    print(\"\\nSample context (first excerpt):\")\n",
    "    first_chunk = response.context.chunks[0]\n",
    "    print(f\"Meeting: {first_chunk['filename']} ({first_chunk['date'][:10]})\")\n",
    "    print(f\"Preview: {first_chunk['chunk_text'][:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "This notebook demonstrates the core capabilities of Phase 3 AI analysis:\n",
    "\n",
    "### What We've Built:\n",
    "✅ **Intelligent Q&A System**: Ask natural language questions about Fed Minutes content  \n",
    "✅ **Period Summarization**: Generate comprehensive summaries of Fed discussions during specific timeframes  \n",
    "✅ **Topic Evolution**: Track how Fed thinking evolved on key topics over time  \n",
    "✅ **Comparative Analysis**: Compare Fed discussions between different periods  \n",
    "✅ **Citation System**: All answers include references to source meetings  \n",
    "✅ **Confidence Scoring**: Quality assessment for each analysis  \n",
    "\n",
    "### Key Features:\n",
    "- **RAG Pipeline**: Combines semantic search with LLM analysis\n",
    "- **Multi-Provider Support**: Works with OpenAI, Anthropic, or mock responses\n",
    "- **Temporal Analysis**: Date-aware search and analysis\n",
    "- **Research-Ready**: Designed for academic and policy research\n",
    "\n",
    "### Try These Research Questions:\n",
    "- \"How did the Fed view international cooperation during the Bretton Woods crisis?\"\n",
    "- \"What were the main disagreements in Fed meetings during 1971?\"\n",
    "- \"How did Fed concerns about unemployment change from 1969 to 1973?\"\n",
    "- \"What role did William McChesney Martin play in monetary policy decisions?\"\n",
    "\n",
    "### Phase 4 Vision:\n",
    "- **Automated Research Reports**: Generate comprehensive analysis documents\n",
    "- **Pattern Recognition**: Discover hidden relationships and trends\n",
    "- **Decision Tree Analysis**: Map Fed decision-making processes\n",
    "- **Interactive Dashboard**: Web interface for researchers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}